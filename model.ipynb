{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gMiuHI49XHRS",
        "collapsed": true
      },
      "outputs": [],
      "source": [
        "!pip install chess"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "x3ALIcm752O2"
      },
      "outputs": [],
      "source": [
        "#imports\n",
        "import kagglehub\n",
        "\n",
        "import os\n",
        "import psutil\n",
        "import time\n",
        "from io import StringIO\n",
        "from multiprocessing import Pool, cpu_count\n",
        "from functools import lru_cache\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "\n",
        "import chess\n",
        "import chess.engine\n",
        "import chess.pgn\n",
        "import chess.polyglot\n",
        "\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, Input\n",
        "from tensorflow.python.keras.engine import data_adapter"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "A8-G-SFP6Rtl"
      },
      "outputs": [],
      "source": [
        "#loading data and defining model save address\n",
        "columnsUsed = ['Result', 'pgn', 'WhiteElo', 'BlackElo']\n",
        "path = kagglehub.dataset_download(\"dimitrioskourtikakis/gm-games-chesscom\")\n",
        "\n",
        "model_path = '/content/ChessModel' #enter your own model path here\n",
        "os.makedirs(model_path, exist_ok = True) #creates folder in case folder isnt already made"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#reading data\n",
        "df = pd.read_csv(f\"{path}/GM_games_dataset.csv\", usecols = columnsUsed)\n",
        "print(df.columns)"
      ],
      "metadata": {
        "id": "GYw7-LSlps_q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fhDBNs9iVeWv"
      },
      "outputs": [],
      "source": [
        "#filtering data so that games are above a certain quality of play\n",
        "data = df[\n",
        "    (df['WhiteElo'] > 2700) &\n",
        "    (df['BlackElo'] > 2700)\n",
        "]\n",
        "\n",
        "print(f\"Filtered data size: {data.shape}\")\n",
        "data.to_csv(\"filtered_gm_games.csv\", index = False)\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#constants for multi + batch processing\n",
        "chunk_size = 10000 #number of rows per chunk\n",
        "chunk_dir = \"/content/processed_chunks\" #place your own file directory here\n",
        "os.makedirs(chunk_dir, exist_ok = True)\n",
        "num_processes = psutil.cpu_count(logical=True)\n",
        "print(f'{num_processes} processes')"
      ],
      "metadata": {
        "id": "Y3I-2RNkqfKb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#some function that helps with how tf reads the data. Found it online after facing an error and it holds everything together. (https://jcbsv.net/2024/04/19/fix-tensorflow-missing-attribute-problem/)\n",
        "def _is_distributed_dataset(ds):\n",
        "    return isinstance(ds, data_adapter.input_lib.DistributedDatasetSpec)\n",
        "\n",
        "data_adapter._is_distributed_dataset = _is_distributed_dataset"
      ],
      "metadata": {
        "id": "dbRnSG3vrwie"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FYfyjffN6UyD"
      },
      "outputs": [],
      "source": [
        "#preprocessing functions\n",
        "def pgnToFen(pgn):\n",
        "  fen_positions = []\n",
        "  pgn_file = StringIO(pgn)\n",
        "  game = chess.pgn.read_game(pgn_file)\n",
        "  board = game.board()\n",
        "  for move in game.mainline_moves():\n",
        "    board.push(move)\n",
        "    fen_positions.append(board.fen())\n",
        "\n",
        "  return fen_positions\n",
        "\n",
        "def chunk_processing(chunk, num_processes):\n",
        "  def parallel_parse(pgnList):\n",
        "    with Pool(processes = num_processes) as pool:\n",
        "      return pool.map(pgnToFen, pgnList)\n",
        "\n",
        "  tempFens = parallel_parse(chunk['pgn'])\n",
        "  fens = [';'.join(fen) for fen in tempFens]\n",
        "  return fens\n",
        "\n",
        "\n",
        "def preprocessing(df, chunkSize, num_processes):\n",
        "  df['FENs'] = None\n",
        "  processedChunks = []\n",
        "  numChunks = (len(df) + chunk_size - 1) // chunkSize\n",
        "\n",
        "  result_mapping = {\n",
        "      \"1-0\" : 1,\n",
        "      \"0-1\" : 0,\n",
        "      \"1/2-1/2\" : 0.5\n",
        "  } # to calculate win probability\n",
        "  df['result'] = df['Result'].map(result_mapping)\n",
        "\n",
        "  for i in range(numChunks):\n",
        "    start = i * chunk_size\n",
        "    end = min((i + 1) * chunk_size, len(df))\n",
        "    chunk = df.iloc[start : end].copy()\n",
        "    print(f\"Processing Chunk {i} ; rows {start} - {end}\")\n",
        "    df.iloc[start:end, df.columns.get_loc('FENs')] = chunk_processing(chunk, num_processes)\n",
        "  return df[['FENs', 'result']]"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#preprocessing the data\n",
        "processed_data = preprocessing(data, chunk_size, num_processes)\n",
        "print(processed_data.head())"
      ],
      "metadata": {
        "id": "Tq_MZHr8qmmi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#cleaning functions\n",
        "def validFen(fen):\n",
        "  components = fen.split(' ')\n",
        "  if len(components) != 6:\n",
        "    return False #FENs consist of 6 different segments\n",
        "\n",
        "  boardComponent = components[0]\n",
        "  ranks = boardComponent.split('/')\n",
        "  if len(ranks) != 8:\n",
        "    return False #The first segment consists of data about all 8 ranks on the chess board\n",
        "\n",
        "  for rank in ranks:\n",
        "    count = 0\n",
        "    for char in rank:\n",
        "      if char.isdigit():\n",
        "        count += int(char)\n",
        "      elif char in 'prbnqkPRBNQK':\n",
        "        count += 1\n",
        "      else:\n",
        "        return False #The rank data consists of either piece notation or numbers (numbers indicate empty squares on the board)\n",
        "\n",
        "  return True\n",
        "\n",
        "def cleaner(processed_data):\n",
        "  validRows = []\n",
        "  validResults = []\n",
        "  totalrows = len(processed_data)\n",
        "  for index, (_, row) in enumerate(processed_data.iterrows()):\n",
        "    fens = row['FENs'].split(';')\n",
        "    validFENs = [fen for fen in fens if validFen(fen)]\n",
        "\n",
        "    if validFENs:\n",
        "      validRows.append(';'.join(validFENs))\n",
        "      validResults.append(row['result'])\n",
        "    if index % 1000 == 0 or index == totalrows:\n",
        "      print(f'Cleaned {index}/{totalrows} rows')\n",
        "\n",
        "  cleanData = processed_data.copy()\n",
        "  cleanData['FENs'] = validRows\n",
        "  cleanData['result'] = validResults\n",
        "  print('Cleaning complete')\n",
        "  return cleanData"
      ],
      "metadata": {
        "id": "HK4ZiFubhaRJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Bnht8I3g6csX",
        "collapsed": true
      },
      "outputs": [],
      "source": [
        "#defining feature vectors\n",
        "\n",
        "def fenToVector(fen):\n",
        "  board = chess.Board(fen)\n",
        "  piece_map = board.piece_map()\n",
        "  features = np.zeros(64)\n",
        "\n",
        "  for square, piece in piece_map.items():\n",
        "    features[square] = piece.piece_type * (1 if piece.color == chess.WHITE else -1)\n",
        "  return features\n",
        "\n",
        "def processChunk(args):\n",
        "  chunk, chunk_id = args\n",
        "  chunk_features = []\n",
        "  chunk_results = []\n",
        "\n",
        "  for _, row in chunk.iterrows():\n",
        "    for fen in row['FENs'].split(';'):\n",
        "      feature = fenToVector(fen)\n",
        "      if feature is not None:\n",
        "        chunk_features.append(feature)\n",
        "        chunk_results.append(row['result'])\n",
        "\n",
        "\n",
        "  features_path = os.path.join(chunk_dir, f\"features_chunk_{chunk_id}.npy\")\n",
        "  results_path = os.path.join(chunk_dir, f\"results_chunk_{chunk_id}.npy\")\n",
        "  np.save(features_path, np.array(chunk_features))\n",
        "  np.save(results_path, np.array(chunk_results))\n",
        "\n",
        "  return chunk_id\n",
        "\n",
        "#processing to disk to save RAM\n",
        "def processToDisk(cleanData, num_processes = None, chunk_size = 1000):\n",
        "    if num_processes is None:\n",
        "        num_processes = cpu_count()\n",
        "\n",
        "    total_rows = len(cleanData)\n",
        "    print(f\"Starting processing for {total_rows} rows using {num_processes} processes...\")\n",
        "\n",
        "    chunks = [(cleanData.iloc[i:i + chunk_size], index) for index, i in enumerate(range(0, total_rows, chunk_size))]\n",
        "\n",
        "    with Pool(processes=num_processes) as pool:\n",
        "        for i, chunk_id in enumerate(pool.imap_unordered(processChunk, chunks), start=1):\n",
        "            print(f\"Processed chunk {chunk_id + 1}/{len(chunks)}...\")\n",
        "\n",
        "    print(\"All chunks processed and saved to disk.\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#clean and process data\n",
        "cleanData = cleaner(processed_data)\n",
        "processToDisk(cleanData, num_processes, chunk_size = 1000)"
      ],
      "metadata": {
        "id": "q1NXxZo9rBOL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9B3bBiQl6lqp",
        "collapsed": true
      },
      "outputs": [],
      "source": [
        "#model\n",
        "batch_size = 64\n",
        "\n",
        "if not os.path.exists(chunk_dir):\n",
        "    raise ValueError(f\"Directory {chunk_dir} does not exist.\")\n",
        "\n",
        "chunk_files = sorted([os.path.join(chunk_dir, f) for f in os.listdir(chunk_dir) if f.startswith(\"features_chunk_\")])\n",
        "\n",
        "if not chunk_files:\n",
        "    raise ValueError(\"No chunk files found in the directory.\")\n",
        "print(f\"Total chunks: {len(chunk_files)} files\")\n",
        "\n",
        "train_chunk_files, test_chunk_files = train_test_split(chunk_files, test_size = 0.2, random_state = 42)\n",
        "print(f\"Train chunks: {len(train_chunk_files)} files\")\n",
        "print(f\"Validation chunks: {len(test_chunk_files)} files\")\n",
        "\n",
        "def data_generator(chunk_files, batch_size):\n",
        "  while True:\n",
        "    for chunk_file in chunk_files:\n",
        "      features = np.load(chunk_file)\n",
        "      results_file = chunk_file.replace(\"features_chunk_\", \"results_chunk_\")\n",
        "      results = np.load(results_file)\n",
        "\n",
        "      for i in range(0, len(features), batch_size):\n",
        "        X_batch = features[i:i + batch_size]\n",
        "        y_batch = results[i:i + batch_size]\n",
        "        yield X_batch, y_batch\n",
        "\n",
        "\n",
        "model = Sequential([\n",
        "    Input(shape = (32, 64)),\n",
        "    Dense(128, activation='relu'),\n",
        "    Dense(64, activation='relu'),\n",
        "    Dense(1, activation='sigmoid')\n",
        "])\n",
        "\n",
        "model.compile(optimizer = 'adam', loss = 'mse', metrics = ['mae'])\n",
        "\n",
        "epochSteps = sum(len(np.load(f)) for f in train_chunk_files) // batch_size\n",
        "valSteps = sum(len(np.load(f)) for f in test_chunk_files) // batch_size\n",
        "\n",
        "print(f'steps per epoch: {epochSteps}')\n",
        "print(f'steps per epoch * epochs = {(epochSteps * 10) // batch_size} batches')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "trainingds = data_generator(train_chunk_files, batch_size)\n",
        "validationds = data_generator(test_chunk_files, batch_size)\n",
        "\n",
        "model.fit(trainingds,\n",
        "          epochs = 10,\n",
        "          steps_per_epoch = epochSteps,\n",
        "          validation_data = validationds,\n",
        "          validation_steps = valSteps)\n",
        "\n",
        "\n",
        "test_gen = data_generator(test_chunk_files, batch_size)\n",
        "test_loss, test_mae = model.evaluate(test_gen, steps = valSteps)\n",
        "print(f\"Test loss: {test_loss}, Test MAE: {test_mae}\")"
      ],
      "metadata": {
        "id": "rFeriqxoHHNU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.compiled = True\n",
        "model.summary()"
      ],
      "metadata": {
        "id": "muU9IBlVWUHZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.save('/content/ChessModel/model.keras') #replace with your own directory"
      ],
      "metadata": {
        "id": "qjOJzcHIKkME"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "loaded_model = tf.keras.models.load_model('/content/drive/MyDrive/ChessModel/newModel.keras')\n",
        "loaded_model.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qbKWOXgRcp8v",
        "outputId": "1293a5f6-89c5-43fc-faa2-4783e344472f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " dense (Dense)               (None, 32, 128)           8320      \n",
            "                                                                 \n",
            " dense_1 (Dense)             (None, 32, 64)            8256      \n",
            "                                                                 \n",
            " dense_2 (Dense)             (None, 32, 1)             65        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 16641 (65.00 KB)\n",
            "Trainable params: 16641 (65.00 KB)\n",
            "Non-trainable params: 0 (0.00 Byte)\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def fenToVector(fen):\n",
        "  board = chess.Board(fen)\n",
        "  piece_map = board.piece_map()\n",
        "  features = np.zeros(64)\n",
        "\n",
        "  for square, piece in piece_map.items():\n",
        "    features[square] = piece.piece_type * (1 if piece.color == chess.WHITE else -1)\n",
        "  return features\n",
        "\n",
        "def winProb(fen):\n",
        "   featureVector = fenToVector(fen)\n",
        "   featureVector = featureVector.reshape(1, 64)\n",
        "   featureVector = np.tile(featureVector,(1, 32, 1))\n",
        "   prob = loaded_model.predict(featureVector, verbose = 0)[0][0]\n",
        "   return prob.item()\n",
        "\n",
        "transpositionTable = {}"
      ],
      "metadata": {
        "id": "j-f5XqbPiHqP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def moveOrdering(board):\n",
        "  #order move searches (checks, captures, attacks)\n",
        "  pieceValue = {\n",
        "      chess.PAWN: 1,\n",
        "      chess.BISHOP: 3,\n",
        "      chess.KNIGHT: 3,\n",
        "      chess.ROOK: 5,\n",
        "      chess.QUEEN: 9,\n",
        "      chess.KING: 0\n",
        "  }\n",
        "  def scoreMove(move):\n",
        "    board.push(move)\n",
        "    if board.is_checkmate():\n",
        "      board.pop()\n",
        "      return 50\n",
        "    board.pop()\n",
        "    if move.promotion is not None: return 20\n",
        "    if board.is_capture(move):\n",
        "      captured = board.piece_at(move.to_square)\n",
        "      capturedValue = pieceValue[captured.piece_type] if captured else 0\n",
        "      capturing = board.piece_at(move.from_square)\n",
        "      capturingValue = pieceValue[capturing.piece_type] if capturing else 0\n",
        "      materialWon = capturedValue - capturingValue\n",
        "      return 10 + materialWon\n",
        "    if board.gives_check(move): return 9\n",
        "    return 0\n",
        "  moves = list(board.legal_moves)\n",
        "\n",
        "  return sorted(moves, key = scoreMove, reverse = True)"
      ],
      "metadata": {
        "id": "VCACDXq5u081"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def minimax(board, depth, alpha, beta, player):\n",
        "  if depth == 0 or board.is_game_over():\n",
        "    return winProb(board.fen()), None\n",
        "\n",
        "  legalMoves = moveOrdering(board)\n",
        "  bestMove = legalMoves[0]\n",
        "  if player: #player = True for white\n",
        "    maxEval = float('-inf')\n",
        "    for move in moveOrdering(board):\n",
        "      board.push(move)\n",
        "      eval, _ = minimax(board, depth - 1, alpha, beta, False)\n",
        "      board.pop()\n",
        "      maxEval = max(maxEval, eval)\n",
        "      alpha = max(alpha, maxEval)\n",
        "      if eval > maxEval:\n",
        "        maxEval = eval\n",
        "        bestMove = move\n",
        "      if beta <= alpha:\n",
        "        break\n",
        "    return maxEval, bestMove\n",
        "  else:\n",
        "    minEval = float('inf')\n",
        "    for move in board.legal_moves:\n",
        "      board.push(move)\n",
        "      eval, _ = minimax(board, depth - 1, alpha, beta, True)\n",
        "      board.pop()\n",
        "      minEval = min(minEval, eval)\n",
        "      beta = min(beta, minEval)\n",
        "      print(f'Evaluating {move}:\\n  Best Move: {bestMove} [{minEval}]\\n  Eval: {eval}')\n",
        "      if eval < minEval:\n",
        "        minEval = eval\n",
        "        bestMove = move\n",
        "      if beta <= alpha:\n",
        "        break\n",
        "    return minEval, bestMove\n",
        "\n",
        "def iterativeDeepening(board, maxDepth, timeLimit):\n",
        "  start = time.time()\n",
        "  player = board.turn\n",
        "  for depth in range(1, maxDepth + 1):\n",
        "    elapsed = time.time() - start\n",
        "    if elapsed > timeLimit:\n",
        "      break\n",
        "    bestScore, bestMove = minimax(board, depth, float('-inf'), float('inf'), player)\n",
        "    print(f\"Best Move: {bestMove} (Score: {bestScore:}) found in {elapsed:.2f}s at depth {depth}\")\n",
        "\n",
        "  return bestMove, bestScore"
      ],
      "metadata": {
        "id": "I6MBfT-6k3uO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sampleFen = 'r3k2r/pppqbppp/8/3PP3/3p2n1/8/PPP3PP/RNBQ1RK1 w - - 0 13'\n",
        "board = chess.Board(sampleFen)\n",
        "maxDepth = 3\n",
        "timeLimit = 15\n",
        "player = board.turn\n",
        "#bestmove, bestEval = iterativeDeepening(board, maxDepth, timeLimit)\n",
        "#print(f'Best Move: {bestmove} with Eval {bestEval}')\n",
        "print(winProb(sampleFen))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 211
        },
        "collapsed": true,
        "id": "KLzR-uvQlo6t",
        "outputId": "32c09c88-6813-4efc-8992-7f11119299f8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "name 'chess' is not defined",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-1-9bf4c756585a>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0msampleFen\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'r3k2r/pppqbppp/8/3PP3/3p2n1/8/PPP3PP/RNBQ1RK1 w - - 0 13'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mboard\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mchess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mBoard\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msampleFen\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mmaxDepth\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m3\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mtimeLimit\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m15\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mplayer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mboard\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mturn\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'chess' is not defined"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "machine_shape": "hm"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}